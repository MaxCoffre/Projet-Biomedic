{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d434561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "492710f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Bacteria_dataset_Multiresictance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2004ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Email',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184c13b",
   "metadata": {},
   "source": [
    "Nettoyage de la colonne Souches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6489b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Souches']=df['Souches'].fillna('')\n",
    "\n",
    "#Fonction qui supprime l'ID de la souche\n",
    "def drop_id(souche):\n",
    "  for i in range(1,len(souche)):\n",
    "    if souche[i].isalpha():\n",
    "      return souche[i:]\n",
    "  return souche\n",
    "\n",
    "df['Souches'] = df['Souches'].apply(drop_id)\n",
    "\n",
    "#Standardisation de Escherichia coli\n",
    "df['Souches'] = df['Souches'].replace(['E.coi','E.cli','E. coli'],'Escherichia coli')\n",
    "#Standardisation de Proteus mirabilis\n",
    "df['Souches'] = df['Souches'].replace(['Proeus mirabilis', 'Prot.eus mirabilis', 'Protus mirabilis'],'Proteus mirabilis')\n",
    "#Standardisation de Enterobacteria spp.\n",
    "df['Souches'] = df['Souches'].replace(['Enter.bacteria spp.','Enteobacteria spp.'], 'Enterobacteria spp.')\n",
    "#Standardisation de Klebsiella pneumoniae\n",
    "df['Souches'] = df['Souches'].replace(['Klbsiella pneumoniae', 'Klebsie.lla pneumoniae'], 'Klebsiella pneumoniae')\n",
    "#Standardisation des Nan\n",
    "df['Souches'] = df['Souches'].replace(['', '?','issing'], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d1d7f",
   "metadata": {},
   "source": [
    "Les lignes qui ont le même ID_souche n'ont pas le même ID général, ni le même nom de patient... cela ressemble à des erreurs. J'ai donc supprimé cet ID qui ne correspond ni au type de bactérie, ni au nom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18950d37",
   "metadata": {},
   "source": [
    "Nettoyage des colonnes d'antibiotiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77240adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_atb = ['AMX/AMP', 'AMC', 'CZ', 'FOX', 'CTX/CRO', 'IPM', 'GEN', 'AN', 'Acide nalidixique', 'ofx', 'CIP', 'C', 'Co-trimoxazole', 'Furanes','colistine']\n",
    "#Première boucle pour standardiser les R, S et I\n",
    "for c in col_atb:\n",
    "    df[c]= df[c].str.upper().replace(['MISSING', '?'],np.nan)\n",
    "    df[c] = df[c].replace('INTERMEDIATE','I')\n",
    "\n",
    "#fonction qui transforme les R, S et I en numérique\n",
    "def quantif(x):\n",
    "    if x == 'R':\n",
    "        return 1\n",
    "    elif x == 'I':\n",
    "        return 0.5\n",
    "    elif x == 'S':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#application de la fonction\n",
    "df[col_atb] = df[col_atb].map(quantif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc46d60",
   "metadata": {},
   "source": [
    "Nettoyage des dates :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b5aea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "594ab366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe temporaire pour travailler dessus\n",
    "dates_temp=df['Collection_Date']\n",
    "\n",
    "#Etape 1 : standardiser les valeurs manquantes\n",
    "dates_temp = dates_temp.replace(['error','missing','?'],np.nan)\n",
    "\n",
    "#Etape 2 : remplacer 08/05/2021 par 2021-05-08 (8 Mai 2021, on le sait car c'est indiqué sur Kaggle)\n",
    "def date_clean(d):\n",
    "    try:\n",
    "        if (re.search(r\"(\\d{4})-(\\d{2})-(\\d{2})\",d) == None) :\n",
    "            return re.sub(r\"(\\d{2})/(\\d{2})/(\\d{4})\", r\"\\3-\\2-\\1\", d)\n",
    "        else : \n",
    "            return d\n",
    "    except:\n",
    "        return d\n",
    "    \n",
    "dates_temp =dates_temp.apply(date_clean)\n",
    "\n",
    "#Etpe 3 : Remplacement des dernières valeurs (ont été repérées par les regex également)\n",
    "dates_temp = dates_temp.replace(['5 Fev 2025','3 Jan 1019'],['2025-02-05','2019-01-03'])\n",
    "\n",
    "#Intégration dans le df principal\n",
    "df['Collection_Date'] = dates_temp\n",
    "\n",
    "#Changement de type\n",
    "df['Collection_Date'] = df['Collection_Date'].astype('datetime64[ns]')\n",
    "\n",
    "#Pour info : repérage des valeurs pas encore transfromées entre les étapes 2 et 3:\n",
    "#df_pas_nan = dates_temp.loc[dates_temp.isna()==False]\n",
    "#df_pas_nan.loc[df_pas_nan.apply(lambda x:re.search(r\"(\\d{4})-(\\d{2})-(\\d{2})\",x) == None)].unique()\n",
    "\n",
    "#Et à la fin, pour vérifier que le mois est bien à sa place, on doit obtenir 2 en premier\n",
    "#df['Collection_Date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ff8c4",
   "metadata": {},
   "source": [
    "Nettoyage Adresses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "251144a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Dictionnaire abréviation → nom complet ===\n",
    "etat_noms_complets = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "    'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "    'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming',\n",
    "    'DC': 'District of Columbia'\n",
    "}\n",
    "\n",
    "# === Fonctions d'extraction ===\n",
    "\n",
    "# Extraire État et Code Postal\n",
    "def extraire_etat_cp(adresse):\n",
    "    match = re.search(r',\\s*([A-Z]{2})\\s+(\\d{5})$', adresse)\n",
    "    if match:\n",
    "        etat = match.group(1)\n",
    "        code_postal = match.group(2)\n",
    "        return pd.Series([etat, code_postal])\n",
    "    return pd.Series(['', ''])\n",
    "\n",
    "# Convertir abréviation en nom complet\n",
    "def etat_nom_complet(abbr):\n",
    "    return etat_noms_complets.get(abbr, '')\n",
    "\n",
    "# Déduire le pays à partir de l’État\n",
    "def etat_vers_pays(etat):\n",
    "    return 'United States' if etat in etat_noms_complets else ''\n",
    "\n",
    "# Extraire la ville approximative\n",
    "def extraire_ville(adresse):\n",
    "    match = re.search(r',\\s*(.*?)\\s*,\\s*[A-Z]{2}\\s+\\d{5}$', adresse)\n",
    "    return match.group(1) if match else ''\n",
    "\n",
    "# === Application des fonctions ===\n",
    "df[['Etat', 'Code_Postal']] = df['Address'].apply(extraire_etat_cp)\n",
    "df['Etat_Complet'] = df['Etat'].apply(etat_nom_complet)\n",
    "df['Pays'] = df['Etat'].apply(etat_vers_pays)\n",
    "df['Ville'] = df['Address'].apply(extraire_ville)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f70e53",
   "metadata": {},
   "source": [
    "Nettoyage Facteurs risque et Infection Freq :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52bafd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Diabetes'] = df['Diabetes'].replace(['No','True','?'],[False, True, np.nan])\n",
    "#df['Diabetes'] = df['Diabetes'].replace('True',True)\n",
    "#df['Diabetes'] = df['Diabetes'].replace('?',np.nan)\n",
    "df['Diabetes'] = df['Diabetes'].replace('missing',np.nan)\n",
    "df['Hypertension'] = df['Hypertension'].replace('No',False)\n",
    "df['Hypertension'] = df['Hypertension'].replace('Yes',True)\n",
    "df['Hypertension'] = df['Hypertension'].replace('?',np.nan)\n",
    "df['Hypertension'] = df['Hypertension'].replace('missing',np.nan)\n",
    "df['Hospital_before'] = df['Hospital_before'].replace('No',False)\n",
    "df['Hospital_before'] = df['Hospital_before'].replace('Yes',True)\n",
    "df['Hospital_before'] = df['Hospital_before'].replace('?',np.nan)\n",
    "df['Hospital_before'] = df['Hospital_before'].replace('missing',np.nan)\n",
    "df['Infection_Freq'] = pd.to_numeric(df['Infection_Freq'], errors='coerce').astype('Int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27caba",
   "metadata": {},
   "source": [
    "Nettoyage age, genre et name :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b586ded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Name' transformed to 'ID Name' and unique IDs assigned.\n",
      "Column 'age/gender' successfully split into 'age' and 'gender'.\n",
      "Column 'age' successfully converted to integer type (Int64).\n"
     ]
    }
   ],
   "source": [
    "# 2. Transformer 'Name' to 'ID Name' avec numero unique\n",
    "if 'Name' in df.columns:\n",
    "    name_to_id = {name: i for i, name in enumerate(df['Name'].unique())}\n",
    "    df['Name'] = df['Name'].map(name_to_id)\n",
    "    df = df.rename(columns={'Name': 'ID Name'})\n",
    "    print(\"Column 'Name' transformed to 'ID Name' and unique IDs assigned.\")\n",
    "else:\n",
    "    print(\"Column 'Name' not found. It might have already been transformed to 'ID Name'.\")\n",
    "\n",
    "# 4. Séparer 'age/gender' et faire deux colonnes\n",
    "if 'age/gender' in df.columns:\n",
    "    df[['age', 'gender']] = df['age/gender'].str.split('/', expand=True)\n",
    "    df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "    df = df.drop(columns=['age/gender'])\n",
    "    print(\"Column 'age/gender' successfully split into 'age' and 'gender'.\")\n",
    "else:\n",
    "    print(\"Column 'age/gender' not found in the DataFrame.\")\n",
    "\n",
    "# 5. Convertir le type colonne 'age' \n",
    "if 'age' in df.columns:\n",
    "    df['age'] = df['age'].astype('Int64')\n",
    "    print(\"Column 'age' successfully converted to integer type (Int64).\")\n",
    "else:\n",
    "    print(\"Column 'age' not found in the DataFrame.\")\n",
    "\n",
    "#df = df[final_column_order]\n",
    "#print(\"Columns 'age' and 'gender' reordered after 'ID Name'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beb18bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID Name</th>\n",
       "      <th>Souches</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Hospital_before</th>\n",
       "      <th>Infection_Freq</th>\n",
       "      <th>AMX/AMP</th>\n",
       "      <th>AMC</th>\n",
       "      <th>CZ</th>\n",
       "      <th>...</th>\n",
       "      <th>C</th>\n",
       "      <th>Co-trimoxazole</th>\n",
       "      <th>Furanes</th>\n",
       "      <th>colistine</th>\n",
       "      <th>Collection_Date</th>\n",
       "      <th>Etat_Complet</th>\n",
       "      <th>Pays</th>\n",
       "      <th>Ville</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S290</td>\n",
       "      <td>0</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>United States</td>\n",
       "      <td>Paulfurt</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S291</td>\n",
       "      <td>1</td>\n",
       "      <td>Morganella morganii</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>United States</td>\n",
       "      <td>South Tanyatown</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S292</td>\n",
       "      <td>2</td>\n",
       "      <td>Proteus mirabilis</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>United States</td>\n",
       "      <td>North Benjamin</td>\n",
       "      <td>77</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S293</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>United States</td>\n",
       "      <td>Andrewbury</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S294</td>\n",
       "      <td>4</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Maine</td>\n",
       "      <td>United States</td>\n",
       "      <td>Torresmouth</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  ID Name              Souches Diabetes Hypertension Hospital_before  \\\n",
       "0  S290        0     Escherichia coli    False        False           False   \n",
       "1  S291        1  Morganella morganii     True        False           False   \n",
       "2  S292        2    Proteus mirabilis     True        False           False   \n",
       "3  S293        3                  NaN      NaN          NaN             NaN   \n",
       "4  S294        4     Escherichia coli    False         True           False   \n",
       "\n",
       "   Infection_Freq  AMX/AMP  AMC   CZ  ...    C  Co-trimoxazole  Furanes  \\\n",
       "0               0      1.0  1.0  1.0  ...  1.0             0.0      0.0   \n",
       "1               3      0.0  1.0  0.0  ...  0.0             0.0      0.0   \n",
       "2               3      0.0  1.0  0.0  ...  1.0             0.0      0.0   \n",
       "3            <NA>      NaN  NaN  NaN  ...  NaN             NaN      NaN   \n",
       "4               1      0.0  0.0  1.0  ...  0.0             0.0      0.0   \n",
       "\n",
       "   colistine  Collection_Date  Etat_Complet           Pays            Ville  \\\n",
       "0        0.0       2025-02-05  Rhode Island  United States         Paulfurt   \n",
       "1        0.0       2021-05-08        Hawaii  United States  South Tanyatown   \n",
       "2        0.0       2022-05-01        Hawaii  United States   North Benjamin   \n",
       "3        NaN       2020-01-05      Illinois  United States       Andrewbury   \n",
       "4        0.0              NaT         Maine  United States      Torresmouth   \n",
       "\n",
       "    age  gender  \n",
       "0    37       F  \n",
       "1    29       F  \n",
       "2    77       F  \n",
       "3  <NA>     NaN  \n",
       "4    13       F  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Notes', 'Address', 'Etat', 'Code_Postal'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f349a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enlève les lignes dont la souche est absente\n",
    "df = df.loc[df['Souches'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fb066d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changement des types\n",
    "df[['Diabetes','Hypertension','Hospital_before']] = df[['Diabetes','Hypertension','Hospital_before']].astype('boolean')\n",
    "df['ID Name'] = df['ID Name'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad046ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Biomedic_clean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfbb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
